<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>

<property>
  <name>mapred.job.tracker</name>
  <value>YOUR_JOBTRACKER_HOSTNAME:9001</value>
  <description>The host and port that the MapReduce job tracker runs
  at.  If "local", then jobs are run in-process as a single map
  and reduce task.this property in jt-ha should be set to vitual IP
  </description>
</property>

<!-- JT-HA's configuration. total 8 property-->
<property>
  <name>mapred.zookeeper.quorum</name>
  <value>YOUR_ZOOKEEPER_SERVER</value>
  <description>zk server
  </description>
</property>

<property>
  <name>mapred.zookeeper.property.clientPort</name>
  <value>2181</value>
  <description>jt client's clientPort to zk
  </description>
</property>
<property>
  <name>zookeeper.session.timeout</name>
  <value>3000</value>
   <description>jt client's session time to zk
  </description>
</property>

<property>
  <name>mapred.system.dir</name>
  <value>${fs.default.name}/mapred/system</value>
  <description>The directory where MapReduce stores control files. it invalide
  </description>
</property>

<property>
  <name>mapred.jobtracker.restart.recover</name>
  <value>true</value>
  <description>"true" to enable (job) recovery upon restart,
               "false" to start afresh
  </description>
</property>

<property>
  <name>hadoop.job.history.location</name>
  <value>${fs.default.name}/mapred/history</value>
  <description> If job tracker is static the history files are stored
  in this single well known place. If No value is set here, by default,
  it is in the local file system at ${hadoop.log.dir}/history.this for HA, must set into hdfs
  </description>
</property>

<property>
  <name>mapred.jobtracker.job.history.block.size</name>
  <value>1024</value>
  <description>The block size of the job history file. Since the job recovery
               uses job history, its important to dump job history to disk as
               soon as possible. Note that this is an expert level parameter.
               The default value is set to 3 MB.we set to 1024 so small that history can spill to disk quickly.
  </description>
</property>

<property>
  <name>mapreduce.jobtracker.staging.root.dir</name>
  <value>${fs.default.name}/mapred/staging</value>
  <description>The root of the staging area for users' job files
  In practice, this should be the directory where users' home
  directories are located (usually /user),in cloudera hadoop this property instead of mapred.system.dir
  </description>
</property>
<!-- JT-HA's configuration. -->

<property>
  <name>mapred.job.tracker.http.address</name>
  <value>0.0.0.0:50030</value>
  <description>
    The job tracker http server address and port the server will listen on.
    If the port is 0 then the server will start on a free port.
  </description>
</property>

<property>
  <name>mapred.job.tracker.handler.count</name>
  <value>10</value>
  <description>
    The number of server threads for the JobTracker. This should be roughly
    4% of the number of tasktracker nodes.
  </description>
</property>

<property>
  <name>mapred.task.tracker.report.address</name>
  <value>127.0.0.1:0</value>
  <description>The interface and port that task tracker server listens on.
  Since it is only connected to by the tasks, it uses the local interface.
  EXPERT ONLY. Should only be changed if your host does not have the loopback
  interface.</description>
</property>


<property>
  <name>mapred.local.dir</name>
  <value>${hadoop.tmp.dir}/mapred/local</value>
  <description>The local directory where MapReduce stores intermediate
  data files.  May be a comma-separated list of
  directories on different devices in order to spread disk i/o.
  Directories that do not exist are ignored.
  </description>
</property>

<property>
  <name>mapred.system.dir</name>
  <value>${hadoop.tmp.dir}/mapred/system</value>
  <description>The shared directory where MapReduce stores control files.
  </description>
</property>

<property>
  <name>mapred.temp.dir</name>
  <value>${hadoop.tmp.dir}/mapred/temp</value>
  <description>A shared directory for temporary files.
  </description>
</property>

<property>
  <name>mapred.map.tasks</name>
  <value>1</value>
  <description>The default number of map tasks per job.
  Ignored when mapred.job.tracker is "local".
  </description>
</property>

<property>
  <name>mapred.reduce.tasks</name>
  <value>1</value>
  <description>The default number of reduce tasks per job. Typically set to 99%
  of the cluster's reduce capacity, so that if a node fails the reduces can
  still be executed in a single wave.
  Ignored when mapred.job.tracker is "local".
  </description>
</property>

<property>
  <name>hadoop.job.history.user.location</name>
  <value>none</value>
  <description> User can specify a location to store the history files of
  a particular job. If nothing is specified, the logs are stored in
  output directory. The files are stored in "_logs/history/" in the directory.
  User can stop logging by giving the value "none".
  </description>
</property>

<property>
  <name>mapred.child.java.opts</name>
  <value>-Xmx1024m</value>
  <description>Java opts for the task tracker child processes.
  The following symbol, if present, will be interpolated: @taskid@ is replaced
  by current TaskID. Any other occurrences of '@' will go unchanged.
  For example, to enable verbose gc logging to a file named for the taskid in
  /tmp and to set the heap maximum to be a gigabyte, pass a 'value' of:
        -Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid@.gc

  The configuration variable mapred.child.ulimit can be used to control the
  maximum virtual memory of the child processes.
  </description>
</property>

<property>
  <name>mapred.map.tasks.speculative.execution</name> 
  <value>true</value>
  <description>If true, then multiple instances of some map tasks 
               may be executed in parallel.</description>
</property> 
   
<property>
  <name>mapred.reduce.tasks.speculative.execution</name>
  <value>true</value>
  <description>If true, then multiple instances of some reduce tasks
               may be executed in parallel.</description>
</property>

<property>
  <name>io.sort.mb</name>
  <value>100</value>
  <description>The total amount of buffer memory to use while sorting
  files, in megabytes.  By default, gives each merge stream 1MB, which
  should minimize seeks.</description>
</property>

<property>
  <name>io.sort.factor</name>
  <value>50</value>
  <description>The number of streams to merge at once while sorting
  files.  This determines the number of open file handles.</description>
</property> 


<property>
  <name>mapred.output.compression.type</name>
  <value>BLOCK</value>
  <description>If the job outputs are to compressed as SequenceFiles, how should
               they be compressed? Should be one of NONE, RECORD or BLOCK.
  </description>
</property>

<property>
  <name>mapred.tasktracker.reduce.tasks.maximum</name>
  <value>10</value>
  <description>The maximum number of reduce tasks that will be run
  simultaneously by a task tracker.
  </description>
</property>

<property>
  <name>mapred.tasktracker.map.tasks.maximum</name>
  <value>10</value>
  <description>The maximum number of map tasks that will be run
  simultaneously by a task tracker.
  </description>
</property>


<property>
  <name>mapred.reduce.parallel.copies</name>
  <value>10</value>
  <description>The default number of parallel transfers run by reduce
  during the copy(shuffle) phase.
  </description>
</property>

<!-- task scheduler conf -->
<property>
  <name>mapred.jobtracker.taskScheduler</name>
  <value>org.apache.hadoop.mapred.FairScheduler</value>
</property>

<property>
  <name>mapred.fairscheduler.allocation.file</name>
  <value>YOUR_HADOOP_HOME_DIR/conf/fair-scheduler.xml</value>
</property>

<property>
    <name>mapred.fairscheduler.assignmultiple</name>
    <value>true</value>
</property>

<property>
  <name>mapred.fairscheduler.preemption</name>
  <value>false</value>
</property>

<property>
  <name>mapred.fairscheduler.allow.undeclared.pools</name>
  <value>false</value>
</property>

<property>
<name>mapred.fairscheduler.poolnameproperty</name>
<value>mapred.job.queue.name</value>
<description>job.set("mapred.queue.name",pool); // pool is set to either 'high' or 'low' </description>
</property>

<property>
  <name>mapred.queue.names</name>
  <value>default,1_LoadQueue,2_QueryQueue,3_MaintainQueue</value>
</property>

</configuration>